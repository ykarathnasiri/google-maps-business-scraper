{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install selenium pandas openpyxl webdriver-manager requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zu6gar51GI8U",
        "outputId": "ebc607a3-fb27-4404-e8fe-6a828890c04d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.35.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.12/dist-packages (4.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from datetime import datetime\n",
        "import urllib.parse\n",
        "import re\n",
        "\n",
        "# ===== CONFIGURATION =====\n",
        "CONFIG = {\n",
        "    \"district\": \"Colombo\",\n",
        "    \"city\": \"Nugegoda\",\n",
        "    \"country\": \"Sri Lanka\",\n",
        "    \"industry\": \"gyms\",\n",
        "    \"max_results\": 50\n",
        "}\n",
        "\n",
        "def setup_driver():\n",
        "    \"\"\"Setup Chrome WebDriver\"\"\"\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    chrome_options.add_argument('--disable-gpu')\n",
        "    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
        "    chrome_options.add_argument('--window-size=1920,1080')\n",
        "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
        "\n",
        "    service = Service(ChromeDriverManager().install())\n",
        "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
        "    return driver\n",
        "\n",
        "def search_on_google_maps(driver, district, city, country, industry):\n",
        "    \"\"\"Search businesses on Google Maps\"\"\"\n",
        "    search_query = f\"{industry} in {city}, {district}, {country}\"\n",
        "    encoded_query = urllib.parse.quote(search_query)\n",
        "    maps_url = f\"https://www.google.com/maps/search/{encoded_query}\"\n",
        "    driver.get(maps_url)\n",
        "    time.sleep(8)\n",
        "    return True\n",
        "\n",
        "def scroll_and_load_results(driver):\n",
        "    \"\"\"Scroll results panel to load all businesses\"\"\"\n",
        "    try:\n",
        "        scrollable = driver.find_element(By.XPATH, '//div[@role=\"feed\"]')\n",
        "    except:\n",
        "        return\n",
        "\n",
        "    last_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable)\n",
        "    for _ in range(20):\n",
        "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scrollable)\n",
        "        time.sleep(2)\n",
        "        new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable)\n",
        "        if new_height == last_height:\n",
        "            break\n",
        "        last_height = new_height\n",
        "\n",
        "def get_business_links(driver):\n",
        "    \"\"\"Get business links\"\"\"\n",
        "    elements = driver.find_elements(By.XPATH, '//a[contains(@href, \"/maps/place/\")]')\n",
        "    links = [e.get_attribute(\"href\") for e in elements if e.get_attribute(\"href\")]\n",
        "    return list(set(links))[:CONFIG['max_results']]\n",
        "\n",
        "def extract_business_details(driver, business_url):\n",
        "    \"\"\"Extract details for one business\"\"\"\n",
        "    details = {\n",
        "        'Name': '',\n",
        "        'Phone': '',\n",
        "        'Rating': '',\n",
        "        'Address': '',\n",
        "        'Google_Maps_Link': business_url\n",
        "    }\n",
        "\n",
        "    driver.get(business_url)\n",
        "    time.sleep(4)\n",
        "\n",
        "    # Name\n",
        "    try:\n",
        "        details['Name'] = driver.find_element(By.XPATH, '//h1').text.strip()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Rating\n",
        "    try:\n",
        "        rating_element = driver.find_element(By.XPATH, '//span[contains(@aria-label,\"stars\")]')\n",
        "        rating_text = rating_element.text or rating_element.get_attribute('aria-label')\n",
        "        match = re.search(r'(\\d+\\.?\\d*)', rating_text)\n",
        "        if match:\n",
        "            details['Rating'] = match.group(1)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Phone\n",
        "    try:\n",
        "        phone_element = driver.find_element(By.XPATH, '//a[contains(@href, \"tel:\")]')\n",
        "        details['Phone'] = phone_element.get_attribute('href').replace(\"tel:\", \"\").strip()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Address\n",
        "    try:\n",
        "        details['Address'] = driver.find_element(By.XPATH, '//button[@data-item-id=\"address\"]').text.strip()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return details if details['Name'] else None\n",
        "\n",
        "def save_to_excel(business_data_list, city, industry):\n",
        "    \"\"\"Save results to Excel\"\"\"\n",
        "    if not business_data_list:\n",
        "        print(\"❌ No data to save!\")\n",
        "        return\n",
        "\n",
        "    df = pd.DataFrame(business_data_list)\n",
        "    output_file = f\"{industry}_{city}.xlsx\".replace(\" \", \"_\")\n",
        "\n",
        "    with pd.ExcelWriter(output_file, engine='openpyxl', mode='w') as writer:\n",
        "        df.to_excel(writer, sheet_name=f\"{industry}_{city}\"[:31], index=False)\n",
        "\n",
        "    print(f\"✅ Data saved: {output_file} ({len(df)} records)\")\n",
        "\n",
        "def main():\n",
        "    print(f\"🎯 Scraping {CONFIG['industry']} in {CONFIG['city']}, {CONFIG['district']}...\")\n",
        "    driver = setup_driver()\n",
        "    all_business_data = []\n",
        "\n",
        "    try:\n",
        "        search_on_google_maps(driver, CONFIG['district'], CONFIG['city'], CONFIG['country'], CONFIG['industry'])\n",
        "        scroll_and_load_results(driver)\n",
        "        links = get_business_links(driver)\n",
        "\n",
        "        print(f\"🔗 Found {len(links)} businesses\")\n",
        "\n",
        "        for i, link in enumerate(links, 1):\n",
        "            print(f\"[{i}/{len(links)}] Extracting...\")\n",
        "            details = extract_business_details(driver, link)\n",
        "            if details:\n",
        "                all_business_data.append(details)\n",
        "            time.sleep(random.uniform(2, 4))\n",
        "\n",
        "        save_to_excel(all_business_data, CONFIG['city'], CONFIG['industry'])\n",
        "\n",
        "    finally:\n",
        "        driver.quit()\n",
        "        print(\"🔒 Browser closed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POrnjLMFy9SJ",
        "outputId": "cba5cf7a-8500-4fba-a9ab-828ffe0d7934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Scraping gyms in Nugegoda, Colombo...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}